{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "\n",
    "st.set_page_config(page_title=\"EDA Dashboard\", layout=\"wide\")\n",
    "st.title(\"ðŸ“Š Automated EDA Dashboard for Basic EDA\")\n",
    "\n",
    "# Upload dataset\n",
    "uploaded_file = st.file_uploader(\"Upload a CSV file\", type=[\"csv\", \"txt\", \"xlsx\"])\n",
    "\n",
    "\n",
    "if uploaded_file:\n",
    "    try:\n",
    "        if isinstance(uploaded_file, str):\n",
    "            df = pd.read_csv(uploaded_file)\n",
    "        else:\n",
    "            df = pd.read_csv(uploaded_file)\n",
    "        st.subheader(\"Dataset Preview\")\n",
    "        st.dataframe(df.head(10))\n",
    "\n",
    "        #sidebar options\n",
    "        st.sidebar.header(\"EDA & Preprocessing Options\")\n",
    "        show_null_count = st.sidebar.checkbox(\"Show Null Value Counts\", True)\n",
    "        fix_nulls = st.sidebar.checkbox(\"Auto-Fix Nulls\", False)\n",
    "        normalize_data = st.sidebar.checkbox(\"Normalize Numeric Columns\", False)\n",
    "        normalization_method = st.sidebar.selectbox(\"Normalization Method\", [\"Min-Max\", \"Standard\"], index=0)\n",
    "        detect_outliers = st.sidebar.checkbox(\"Detect Outliers (IQR Method)\", False)\n",
    "        target_column = None\n",
    "\n",
    "        show_histograms = st.sidebar.checkbox(\"Show Histogram of Numeric columns\", True)\n",
    "        show_countplots = st.sidebar.checkbox(\"Show Count Plots for catagorical columns\", True)\n",
    "\n",
    "\n",
    "        df_clean = df.copy()\n",
    "\n",
    "        #Null values\n",
    "        if show_null_count:\n",
    "            st.subheader(\"Null Count per column\")\n",
    "            null_count = df_clean.isnull().sum()\n",
    "            st.dataframe(null_count[null_count > 0].sort_values(ascending=False))\n",
    "        if fix_nulls:\n",
    "            st.subheader(\"Auto-Fix Nulls\")\n",
    "            numeric_cols = df_clean.select_dtypes(include=np.number).columns.tolist()\n",
    "            catagorical_cols = df_clean.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "            for col in numeric_cols:\n",
    "                if df_clean[col].isnull().sum() > 0:\n",
    "                    df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "                    st.write(f\"Filled numeric cols {col} with Median\")\n",
    "            for col in catagorical_cols:\n",
    "                if df_clean[col].isnull().sum() > 0:\n",
    "                    df_clean[col].fillna(\"Unknown\", inplace=True)\n",
    "                    st.write(f\"Filled categorical cols {col} with Unknown\")\n",
    "\n",
    "        #Outlier detection\n",
    "        if detect_outliers:\n",
    "            st.subheader(\"Potential Outliers (IQR Method)\")\n",
    "            numeric_cols = df_clean.select_dtypes(include=np.number).columns.tolist()\n",
    "            outlier_dict = {}\n",
    "            for col in numeric_cols:\n",
    "                Q1 = df_clean[col].quantile(0.25)\n",
    "                Q3 = df_clean[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower = Q1 - 1.5 * IQR\n",
    "                upper = Q3 + 1.5 * IQR\n",
    "                outliers = df_clean[(df_clean[col] < lower) | (df_clean[col] > upper)]\n",
    "                if len(outliers) > 0:\n",
    "                    outlier_dict[col] = len(outliers)\n",
    "            if outlier_dict:\n",
    "                st.write(\"Number of outliers detected per column:\")\n",
    "                st.json(outlier_dict)\n",
    "            else:\n",
    "                st.write(\"No significant outliers detected.\")\n",
    "\n",
    "\n",
    "        #Data Normalization\n",
    "        if normalize_data:\n",
    "            numeric_cols = df_clean.select_dtypes(include=np.number).columns.tolist()\n",
    "            st.subheader(\"Normalizing Numeric Columns\")\n",
    "            if normalization_method==\"Min-Max\":\n",
    "                scaler = MinMaxScaler()\n",
    "            else:\n",
    "                scaler = StandardScaler()\n",
    "            df_clean[numeric_cols] = scaler.fit_transform(df_clean[numeric_cols])\n",
    "            st.write(f\"Normalized columns: {numeric_cols} using {normalization_method} scaling\")\n",
    "\n",
    "\n",
    "\n",
    "        #visualization\n",
    "        numeric_cols = df_clean.select_dtypes(include=np.number).columns.tolist()\n",
    "        categorical_cols = df_clean.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "        if show_histograms and numeric_cols:\n",
    "            st.subheader(\"Histograms for Numeric Columns\")\n",
    "            for col in numeric_cols:\n",
    "                fig, ax = plt.subplots()\n",
    "                sns.histplot(df_clean[col], kde=True, ax=ax)\n",
    "                ax.set_title(f\"{col} Distribution\")\n",
    "                st.pyplot(fig)\n",
    "\n",
    "        if show_countplots and categorical_cols:\n",
    "            st.subheader(\"Count Plots for Categorical Columns\")\n",
    "            for col in categorical_cols:\n",
    "                fig, ax = plt.subplots()\n",
    "                sns.countplot(y=df_clean[col], order=df_clean[col].value_counts().index, ax=ax)\n",
    "                ax.set_title(f\"{col} Counts\")\n",
    "                st.pyplot(fig)\n",
    "\n",
    "        # ---------- Download Cleaned Dataset ----------\n",
    "        st.subheader(\"Download Cleaned / Processed Dataset\")\n",
    "        csv = df_clean.to_csv(index=False)\n",
    "        st.download_button(label=\"Download CSV\", data=csv, file_name=\"cleaned_dataset.csv\", mime=\"text/csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(\"Error loading dataset: \" + str(e))\n",
    "else:\n",
    "    st.info(\"Upload a CSV file or use the sample dataset to start exploring.\")\n"
   ],
   "id": "898947fc6f6f2bee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a5c04d4e6f0f753a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "37bf4ef453063db8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e31dc31a4c4e3c43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7bdd90d74b4a7f3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ae3e77c4f7d02813"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
